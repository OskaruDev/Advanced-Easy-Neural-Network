import pandas as pd 
import os
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np
import sys
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
# tensorflow
#import tensorflow
# keras
import keras
from keras.models import Sequential
from keras.layers import Dense
from .untils import readDataset, writeDataset, writeFile, createDirIfNotExist, readFile, writeFileWithJson, deleteFile
from multiprocessing import Process
from .neural import generateCode, updateJson
import json

def executeModel(tempFile):

    content = readFile(tempFile)
    data = json.loads(content)

    userFolderPath = data["userFolderPath"]
    model = data["model"]
    rowData = data["rowData"]
    datasetPath = data["datasetPath"]
    modelName = data["modelName"]

    neuralNetworkFolderPath = os.path.join(userFolderPath, "neuralNetwork")
    modelFolderPath = os.path.join(userFolderPath, "model", "code")
    infoFolderPath = os.path.join(userFolderPath, "model", "info")

    toRet = {}
    dataframe = readDataset(datasetPath)

    X = dataframe[rowData["dataNames"]].values
    Y = dataframe[rowData["targetsNames"]].values
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)


    try:
        
            #Clear Sesion
            keras.backend.clear_session()

            #Create the secuential model
            model = Sequential()

            #Imput Layer
            dimNumber = int(model["firstDimNumber"])
            activation = str(model["firstActivation"])
            model.add(Dense(dimNumber, activation=activation,input_dim=dimNumber))
            
            #Hidden Layers
            for hidenLayer in model["hidenLayers"]:
                dimNumber = int(model["hidenLayers"][hidenLayer]["dimNumber"])
                activation = str(model["hidenLayers"][hidenLayer]["activation"])
                model.add(Dense(dimNumber, activation=activation))
            
            #Output Layer
            dimNumber = int(model["lastDimNumber"])
            activation = str(model["lastActivation"])
            model.add(Dense(dimNumber, activation=activation))

            #Compile the model
            lossFuntion = str(model["lossFuntion"])
            optimicer = str(model["optimicer"])
            model.compile(loss=lossFuntion, optimizer=optimicer)

            #Callbacks
            jsonInfoTrainig = {
                "maxEpoch": model["epochs"],
                "actualEpoch": 0,
                "loss": "Not Obtained", 
                "name": str(modelName),
                #"userOwner": request.user.username
            }
            logger = keras.callbacks.LambdaCallback(
                on_epoch_end=lambda epochs,logs: writeFile(str(updateJson(jsonInfoTrainig, logs["loss"], epochs)), infoFolderPath, str(modelName)+ ".temp"),  
                on_train_end=lambda logs: deleteFile(infoFolderPath, str(modelName)+ ".temp"))


            #Fit the model whith the train data (and indicate the numer of iterations for the data)
            epochs = int(model["epochs"])
            batchSize = int(model["batchSize"])
            model.fit(X_train, y_train, epochs=epochs, batch_size=batchSize, callbacks=[logger])
            
            #Model summary
            print(model.summary())

            # evaluate the model
            lossVal = model.evaluate(X_test, y_test, verbose=0)
            model["lossVal"] = {
                "value": lossVal,
                "metric": lossFuntion
            }
            print(lossVal)

            #Store data and target names
            model["dataNames"] = rowData["dataNames"]
            model["targetsNames"] = rowData["targetsNames"]
            
            #Create model auto-generated code
            autoGeneratedCode = generateCode(model)
            codeModelName = str(modelName).removesuffix('.csv') + ".py"
            writeFile(autoGeneratedCode, modelFolderPath, codeModelName)
            
            #Create NeuralNetwork File
            neuralNetworkName = str(modelName).removesuffix('.csv') + ".keras"
            createDirIfNotExist(neuralNetworkFolderPath)
            neuralNetworkPath = os.path.join(neuralNetworkFolderPath, neuralNetworkName)
            model.save(neuralNetworkPath)

            #Create info File
            infoFileName = str(modelName).removesuffix('.csv') + ".info"
            writeFileWithJson(model, infoFolderPath, infoFileName)
        

    except BaseException as e:
        print("Error -> " + str(e))
        if toRet["messageErr"] is not None:
            toRet.update({"messageErr": "An error occurred in Model " + modelName})
        else:
            toRet.update({"messageErr": toRet["messageErr"] + ", " + modelName})

    return toRet
    
 



def iniciateModels(models, rowData, datasetPath, userFolderPath):
    
    infoFolderPath = os.path.join(userFolderPath, "model", "info")

    for modelName in models:
        #Callbacks
        jsonInfoTrainig = {
            "maxEpoch": models[modelName]["epochs"],
            "actualEpoch": 0,
            "loss": "Not Obtained", 
            "name": str(modelName),
            "rowData": rowData,
            "datasetPath": datasetPath,
            "userFolderPath": userFolderPath,
            "model": models[modelName],
            "modelName": modelName
        }

        writeFile(json.dumps(jsonInfoTrainig), infoFolderPath, str(modelName)+ ".temp")
        tempFile = os.path.join(infoFolderPath, str(modelName)+ ".temp")
        
        process = Process(target=executeModel, args=(tempFile, ))
        process.start()

    return {}
